# Capstone Project: Gaussian Mixture Models (GMM) vs. Traditional Clustering  
## âœï¸ Authors
Binal Patel, Siddhi Naik, Kaleem Mohammed
## ğŸ“– Project Overview  
This project explores **Gaussian Mixture Models (GMM)** as an alternative to traditional clustering techniques, comparing it against **k-Means, Hierarchical Clustering, and DBSCAN** on three benchmark datasets. We analyze how GMMâ€™s **soft clustering** approach handles different data distributions, especially where traditional methods struggle.  

## ğŸ“Š Datasets Used  
We evaluate clustering performance on three synthetic datasets:  
1. **Moons Dataset** â€“ Non-spherical clusters (where GMM is expected to outperform k-Means).  
2. **Blobs Dataset** â€“ Well-separated clusters with varying densities.  
3. **Circles Dataset** â€“ Nested circular clusters (challenging for k-Means).  

## ğŸ” Key Objectives  
- **Understand GMMâ€™s working principles** (Expectation-Maximization, probability-based clustering).  
- **Implement GMM and compare it with k-Means, Hierarchical, and DBSCAN**.  
- **Analyze clustering performance using visualization and metrics (e.g., Silhouette Score, BIC/AIC for GMM).**  

## ğŸ—ï¸ Project Structure  
```
Machine_Learning_Capstone_Project/
â”‚â”€â”€ scripts/
â”‚ â”œâ”€â”€ main.ipynb # Jupyter Notebook with GMM implementation and comparisons
â”‚â”€â”€ plots/ # Clustering output visualizations
â”‚ â”œâ”€â”€ moons_clustering.png # GMM vs. traditional clustering on Moons Dataset
â”‚ â”œâ”€â”€ blobs_clustering.png # GMM vs. traditional clustering on Blobs Dataset
â”‚ â”œâ”€â”€ circles_clustering.png # GMM vs. traditional clustering on Circles Dataset
â”‚â”€â”€ README.md # Project description and instructions
â”‚â”€â”€ report.docx # Final written report
```


## ğŸ–¥ï¸ How to Run the Code
1. **Clone the repository**:
   ```bash
   git clone https://github.com/Kaleem-QADR/Machine_Learning_Capstone_Project.git
   cd Machine_Learning_Capstone_Project/scripts

   ```

2. Open Jupyter Notebook:
```
jupyter notebook main.ipynb
```
3. Run all cells to generate clustering outputs and comparisons.
4. Visualizations will be saved in the plots/ folder.

ğŸ“ˆ Performance Evaluation
Silhouette Score: Measures cluster quality for each method.
BIC & AIC (for GMM): Helps determine the optimal number of Gaussian components.
Clustering Plots: Visual comparison of GMM, k-Means, Hierarchical, and DBSCAN.



ğŸ“Œ References
scikit-learn: GaussianMixture
Expectation-Maximization Algorithm
Clustering Evaluation Metrics

ğŸ“¢ Acknowledgments
Special thanks to our instructor and peers for their support and feedback on this project! ğŸ¯ğŸš€


---

### **What This README Includes**
âœ… **Project Overview**  
âœ… **Authors: Binal Patel, Siddhi Naik, Kaleem Mohammed**  
âœ… **Datasets & Objectives**  
âœ… **File Structure (Matches Your Preferred Format)**  
âœ… **How to Run the Code**  
âœ… **Evaluation Metrics**  
âœ… **References & Acknowledgments**  

---
